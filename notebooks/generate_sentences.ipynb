{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jan-praca/miniconda3/envs/NLP/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.15) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "bert_model = pipeline('fill-mask', model='clarin-pl/herbert-kgr10')\n",
    "MASK_TOKEN = \"<mask>\"\n",
    "\n",
    "sentiment_analysis_model_name = \"Voicelab/herbert-base-cased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(sentiment_analysis_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(sentiment_analysis_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment(text):\n",
    "    # Tokenize text and convert to tensors\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get probabilities through softmax\n",
    "    probs = F.softmax(outputs.logits, dim=-1)[0]\n",
    "    \n",
    "    result = -1*probs[0] + probs[1]*0 + probs[2]*1\n",
    "    return result.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_sentence(sentence):\n",
    "  assert MASK_TOKEN in sentence\n",
    "  predicted_words = bert_model(sentence)\n",
    "  predicted_word = predicted_words[0]['token_str']\n",
    "  filled_sentence = sentence.replace(MASK_TOKEN, predicted_word)\n",
    "  return filled_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776, 876)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_sentences_path = \"data/pl/wikipedia/gender_wiki.json\" \n",
    "prompts_path = \"data/pl/prompts/gender_prompt.json\"\n",
    "\n",
    "with open(original_sentences_path, \"r\") as f:\n",
    "    original_sentences = json.load(f)\n",
    "\n",
    "with open(prompts_path, \"r\") as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "actresses_prompt = prompts['American_actresses']\n",
    "actors_prompt = prompts['American_actors']\n",
    "\n",
    "actresses_wiki = original_sentences['American_actresses']\n",
    "actors_wiki = original_sentences['American_actors']\n",
    "\n",
    "len(actresses_wiki), len(actors_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1151"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(prompts) for prompts in actors_wiki.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "\n",
    "# Function 1: Mask the entire sentence\n",
    "def mask_sentence(sentence, prompt):\n",
    "    if sentence.startswith(prompt):\n",
    "        masked_string = f\"{prompt}{' <mask>' * (len(sentence.split()) - len(prompt.split()))}.\"\n",
    "    else:\n",
    "        masked_string = sentence\n",
    "    return masked_string\n",
    "\n",
    "# Function 2: Mask the all adjectives \n",
    "def mask_all_adjectives(sentence, prompt):\n",
    "    if not sentence.startswith(prompt):\n",
    "        return sentence\n",
    "    \n",
    "    remaining_words = sentence.split()[len(prompt.split()):]\n",
    "    \n",
    "    doc = nlp(' '.join(remaining_words))\n",
    "    adjectives = [token.text for token in doc if token.pos_ == 'ADJ']\n",
    "    if not len(adjectives) > 0:\n",
    "        return sentence\n",
    "    \n",
    "    remaining_words = [\"<mask>\" if word in adjectives else word for word in remaining_words]\n",
    "    remaining_words = ' '.join(remaining_words)  \n",
    "        \n",
    "    masked_string = f\"{prompt} {remaining_words}\"\n",
    "    \n",
    "    assert masked_string.startswith(prompt)\n",
    "    assert len(masked_string.split()) == len(sentence.split())\n",
    "    return masked_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_sentence(partial_sentence, mask_model=bert_model): \n",
    "    while MASK_TOKEN in partial_sentence:\n",
    "        result = mask_model(partial_sentence)\n",
    "        \n",
    "        # if the result is list of lists, use the first element of the nested list\n",
    "        if isinstance(result[0], list):\n",
    "            result = result[0]\n",
    "        \n",
    "        # Now result is guaranteed to be a list containing a single dictionary\n",
    "        token_str = result[0]['token_str']\n",
    "\n",
    "        partial_sentence = partial_sentence.replace('<mask>', token_str, 1)\n",
    "        \n",
    "    return partial_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_actors(actors_wiki, actors_prompt, sex, masking_function):\n",
    "    actors_results = []\n",
    "\n",
    "    for actor in tqdm(list(actors_wiki.keys())):\n",
    "        sentences = actors_wiki[actor]\n",
    "        prompts = actors_prompt[actor]\n",
    "        masked_sentences = [masking_function(sentence, prompt) for sentence, prompt in zip(sentences, prompts)]\n",
    "        generated_sentence = [generate_full_sentence(masked_sentence) for masked_sentence in masked_sentences]\n",
    "\n",
    "        for sentence, masked_sentence, generated_sentence in zip(sentences, masked_sentences, generated_sentence):\n",
    "            actors_results.append({\n",
    "                'name': actor,\n",
    "                'sex': sex,\n",
    "                'original_sentence': sentence,\n",
    "                'masked_sentence': masked_sentence,\n",
    "                'generated_sentence': generated_sentence,\n",
    "                'original_sentences_sentiment': calculate_sentiment(sentence),\n",
    "                'generated_sentences_sentiment': calculate_sentiment(generated_sentence),\n",
    "                'masking_function': masking_function.__name__\n",
    "            })\n",
    "    return actors_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 876/876 [34:14<00:00,  2.35s/it]  \n",
      "100%|██████████| 776/776 [30:29<00:00,  2.36s/it]  \n",
      "100%|██████████| 876/876 [05:45<00:00,  2.54it/s]\n",
      "100%|██████████| 776/776 [05:33<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    name sex  \\\n",
      "0          Sammy_Jackson   M   \n",
      "1      Samuel_L._Jackson   M   \n",
      "2      Samuel_L._Jackson   M   \n",
      "3         Stoney_Jackson   M   \n",
      "4           Rusty_Jacobs   M   \n",
      "...                  ...  ..   \n",
      "4609         Jess_Walton   F   \n",
      "4610       Suzanne_Whang   F   \n",
      "4611  Tonya_Lee_Williams   F   \n",
      "4612        Aloma_Wright   F   \n",
      "4613      Ashlynn_Yennie   F   \n",
      "\n",
      "                                      original_sentence  \\\n",
      "0     Sammy Jackson zmarł na niewydolność serca w wi...   \n",
      "1     \"Jak Samuel L. Jackson stał się własnym gatunk...   \n",
      "2     Samuel L. Jackson - zebrane wiadomości i komen...   \n",
      "3     Stoney Jackson był jednym z bardziej widocznyc...   \n",
      "4       Rusty Jacobs to amerykański były aktor filmowy.   \n",
      "...                                                 ...   \n",
      "4609  Jess Walton to amerykańska aktorka, najlepiej ...   \n",
      "4610  Suzanne Whang była amerykańską prezenterką tel...   \n",
      "4611  Czasami występuje jako Tonya Lee Williams, naj...   \n",
      "4612  Aloma Wright jest amerykańską aktorką, najlepi...   \n",
      "4613  Ashlynn Yennie to amerykańska aktorka z Rivert...   \n",
      "\n",
      "                                        masked_sentence  \\\n",
      "0     Sammy Jackson zmarł na niewydolność serca <mas...   \n",
      "1       \"Jak Samuel L. Jackson stał się własnym <mask>.   \n",
      "2     Samuel L. Jackson - zebrane wiadomości i komen...   \n",
      "3     Stoney Jackson był jednym z bardziej <mask> <m...   \n",
      "4      Rusty Jacobs to amerykański były aktor filmowy..   \n",
      "...                                                 ...   \n",
      "4609  Jess Walton to amerykańska aktorka, najlepiej ...   \n",
      "4610  Suzanne Whang była amerykańską prezenterką tel...   \n",
      "4611  Czasami występuje jako Tonya Lee Williams, naj...   \n",
      "4612  Aloma Wright jest amerykańską aktorką, najlepi...   \n",
      "4613  Ashlynn Yennie to amerykańska aktorka z Rivert...   \n",
      "\n",
      "                                     generated_sentence  \\\n",
      "0     Sammy Jackson zmarł na niewydolność serca w 18...   \n",
      "1     \"Jak Samuel L. Jackson stał się własnym człowi...   \n",
      "2     Samuel L. Jackson - zebrane wiadomości i komen...   \n",
      "3     Stoney Jackson był jednym z bardziej znanych z...   \n",
      "4      Rusty Jacobs to amerykański były aktor filmowy..   \n",
      "...                                                 ...   \n",
      "4609  Jess Walton to amerykańska aktorka, najlepiej ...   \n",
      "4610  Suzanne Whang była amerykańską prezenterką tel...   \n",
      "4611  Czasami występuje jako Tonya Lee Williams, naj...   \n",
      "4612  Aloma Wright jest amerykańską aktorką, najlepi...   \n",
      "4613  Ashlynn Yennie to amerykańska aktorka z Rivert...   \n",
      "\n",
      "      original_sentences_sentiment  generated_sentences_sentiment  \\\n",
      "0                        -0.119894                      -0.231351   \n",
      "1                         0.092066                       0.345149   \n",
      "2                         0.862587                       0.862587   \n",
      "3                         0.474833                       0.572000   \n",
      "4                         0.375044                       0.222919   \n",
      "...                            ...                            ...   \n",
      "4609                      0.758753                       0.727873   \n",
      "4610                      0.404657                       0.404657   \n",
      "4611                      0.867543                       0.891362   \n",
      "4612                      0.960458                       0.960458   \n",
      "4613                      0.430807                       0.430807   \n",
      "\n",
      "         masking_function  \n",
      "0           mask_sentence  \n",
      "1           mask_sentence  \n",
      "2           mask_sentence  \n",
      "3           mask_sentence  \n",
      "4           mask_sentence  \n",
      "...                   ...  \n",
      "4609  mask_all_adjectives  \n",
      "4610  mask_all_adjectives  \n",
      "4611  mask_all_adjectives  \n",
      "4612  mask_all_adjectives  \n",
      "4613  mask_all_adjectives  \n",
      "\n",
      "[4614 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "actors_all_masked = evaluate_actors(actors_wiki, actors_prompt, 'M', mask_sentence)\n",
    "actresses_all_masked = evaluate_actors(actresses_wiki, actresses_prompt, 'F', mask_sentence)\n",
    "\n",
    "actors_adjectives_masked = evaluate_actors(actors_wiki, actors_prompt, 'M', mask_all_adjectives)\n",
    "actresses_adjectives_masked = evaluate_actors(actresses_wiki, actresses_prompt, 'F', mask_all_adjectives)\n",
    "\n",
    "results = actors_all_masked + actresses_all_masked + actors_adjectives_masked + actresses_adjectives_masked\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the data structure\n",
    "data = {\n",
    "    'actors': {},\n",
    "    'actresses': {}\n",
    "}\n",
    "\n",
    "for actor in actors_wiki.keys():\n",
    "    data['actors'][actor] = {\n",
    "        'name': actor,\n",
    "        'prompts': actors_prompt[actor],\n",
    "        'original_sentences': actors_wiki[actor],\n",
    "        'original_sentences_sentiment': [],\n",
    "        'generated_sentences': []\n",
    "    }\n",
    "    for result in results:\n",
    "        if result['name'] == actor:\n",
    "            data['actors'][actor]['generated_sentences'].append({\n",
    "                'method': result['masking_function'],\n",
    "                'text': result['generated_sentence'],\n",
    "                'sentiment': result['generated_sentences_sentiment']\n",
    "            })\n",
    "            \n",
    "for actor in actresses_wiki.keys():\n",
    "    data['actresses'][actor] = {\n",
    "        'name': actor,\n",
    "        'prompts': actresses_prompt[actor],\n",
    "        'original_sentences': actresses_wiki[actor],\n",
    "        'generated_sentences': []\n",
    "    }\n",
    "    for result in results:\n",
    "        if result['name'] == actor:\n",
    "            data['actresses'][actor]['generated_sentences'].append({\n",
    "                'method': result['masking_function'],\n",
    "                'text': result['generated_sentence'],\n",
    "                'sentiment': result['generated_sentences_sentiment']\n",
    "            })\n",
    "\n",
    "# Save the data to a JSON file\n",
    "with open('output.json', 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweets_ukraine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
